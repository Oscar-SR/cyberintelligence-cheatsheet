{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"CyberOps Cheatsheet","text":"<p>Welcome to the CyberOps Cheatsheet, a practical repository on cyber operations, including cyber intelligence, ethical hacking, malware analysis, and digital forensics.  </p> <p>CyberOps (Cyber Operations) refers to the practice of protecting, monitoring, and investigating digital systems, while also understanding offensive techniques used in cybersecurity. It combines defensive and offensive skills to detect, analyze, and respond to cyber threats effectively.</p>"},{"location":"#purpose","title":"Purpose","text":"<p>This repository aims to provide a concise yet structured overview of key concepts, methodologies, tools, and limitations involved in modern cybersecurity work. It is not intended to replace formal training or legal guidance, but to serve as a field reference for analysts, researchers, and students.</p> <p>The content prioritizes: - Practical applicability - Conceptual clarity - Ethical and legal awareness - Operational security considerations</p>"},{"location":"#main-sections","title":"Main Sections","text":"<ul> <li>Cyber Threat Intelligence \u2013 Intelligence cycle, sources, and methodologies.  </li> <li>Ethical Hacking \u2013 Tools, techniques, and best practices for penetration testing and security assessment.  </li> <li>Digital Forensics \u2013 Incident investigation, evidence collection, and forensic analysis of digital systems.  </li> <li>Malware Analysis \u2013 Dynamic and static analysis of malicious software, reverse engineering, and sandbox techniques.</li> </ul>"},{"location":"#living-document","title":"Living document","text":"<p>This cheatsheet is intentionally iterative and evolving. Techniques, platforms, and adversary behaviors change constantly; content may be updated, refined, or expanded over time.</p> <p>Contributions, corrections, and suggestions are welcome, provided they align with responsible and ethical intelligence practices.</p>"},{"location":"#disclaimer","title":"Disclaimer","text":"<p>All information provided here is for educational and research purposes only. Users are responsible for ensuring that their activities comply with applicable laws, regulations, and platform terms of service.</p>"},{"location":"cyber-threat-intelligence/","title":"Introduction","text":"<p>In this section, we are going to learn about collecting, analyzing, and interpreting information from digital and open sources, and how to apply methodologies and best practices to achieve this goal.</p>"},{"location":"cyber-threat-intelligence/#structure","title":"Structure","text":"<p>This section is divided into four main areas:</p> <ol> <li> <p>Fundamentals: Learn about the intelligence cycle, threat actors, indicators of compromise (IOCs), and how to turn raw data into actionable intelligence. Go to Fundamentals \u2192</p> </li> <li> <p>OSINT: Explore techniques and tools for collecting information from publicly available sources, while respecting legal and ethical boundaries. Go to OSINT \u2192</p> </li> <li> <p>SOCMINT: Discover how to analyze social media data and metadata to gain insights about targets, campaigns, or emerging threats. Go to SOCMINT \u2192</p> </li> <li> <p>Dark Web: Understand the types of dark web sites, the risks involved, and the tools used for safe exploration and intelligence gathering. Go to Dark Web \u2192</p> </li> </ol>"},{"location":"cyber-threat-intelligence/#how-to-use","title":"How to use","text":"<ul> <li>Start with Threat Intelligence to understand the fundamentals of cyber intelligence.  </li> <li>Use OSINT and SOCMINT for practical data gathering exercises.  </li> <li>Explore the Dark Web topics with caution, always following ethical and legal guidelines.  </li> <li>Each subsection contains practical examples, tools, and notes for real-world application.</li> </ul>"},{"location":"cyber-threat-intelligence/historical-facts/","title":"Historical facts","text":""},{"location":"cyber-threat-intelligence/historical-facts/#the-king-of-the-dark-web","title":"The king of the Dark Web","text":"<p>In the early 2010s, the Dark Web was gaining momentum. The promises of anonymity and privacy were attracting more and more people. With Bitcoin, there was a new form of payment that wasn't controlled by authorities. It had become easier than ever for criminals to sell their products online at a massive scale.</p> <p>In July 2014, a man using the pseudonym \"Alpha02\" began developing AlphaBay. Just five months later, the platform went live. Initially, only stolen credit card data was offered and sold, but AlphaBay quickly began offering more lucrative products. In addition to data and logins, there were drugs, weapons, and malware. Services such as money laundering were also available. Few things were forbidden, but items or data related to child abuse, hit-and-runs, and stolen bank account information from Russia were strictly prohibited. Alpha02 probably wanted to avoid trouble with Russian law enforcement or perhaps wanted to mislead investigators by pretending to be Russian.</p> <p>American investigators wanted to locate AlphaBay's servers. With access to the servers, they could shut down the platform or infiltrate it to locate the operators. They started browsing the platform and buying drugs anonymously, hoping for any mistakes by the sellers. Perhaps the product\u2019s packaging or postage stamps could provide clues to the identity of the respective drug dealer, allowing them to arrest him. But these were just small fish. Dealers come and go. Investigators wanted Alpha02. However, the mastermind behind AlphaBay seemed to take every precaution and knew every rule of the game. Investigators became desperate until December 2016. Robert Miller, working for the DEA in Fresno, California, received an anonymous email. It seemed like Alpha02 had made a fatal mistake in the early days of AlphaBay. Every user who registered on the website at that time received a welcome email. The sender's email address was visible in the metadata of this email. Although the error was immediately corrected, the anonymous tipster saved one of those first welcome emails. Perhaps the tipster was one of Alpha02's first customers or an operator of a competing site. Regardless, he silently watched AlphaBay grow on the dark web, only to then hand the email address over to the DEA. The email address was pimp_alex_91@hotmail.com.</p> <p>Via the email address, the investigators found photos from 2008 and 2009 of an \"Alex\" on Skyrock.com, a French-language social media platform. He also linked an old dating profile, listing Trois-Rivi\u00e8res as his hometown in southern Quebec, Canada. According to the profile, he was 17 years old at the time. So the 91 in his email address could be the year he was born. He would have been 23 years old when AlphaBay was founded. The username \"Alpha02\" also appeared on a French-language technology forum. They found Caze's PayPal account, which provided his private email address. Through his LinkedIn profile, they discovered he worked as a freelance software designer and ran his own tech company called EBX Technologies. On Facebook, the investigators found the profile of his fianc\u00e9e, a Thai woman, indicating the Canadian lived in Thailand. The clues led investigators to Bangkok.</p> <p>The date of the operation was set for July 5, 2017. Thai police blocked the area around the gated community in the early morning. The agents watched Cazes' house and waited for the right moment. When Cazes heard the crash, he left his laptop and went out to see what happened. The investigators stormed the house. Cazes' laptop was unlocked, and the DEA quickly gained access to the administration tools of AlphaBay. Simultaneously, other agents searched his \"Bachelor Pad.\" Cazes was arrested without putting up a fight.</p> <p>The investigators handed the suspect over to the Thai police. He was initially held at the police station and then transferred to Bangkok's Narcotics Suppression Bureau for questioning. He signed the arrest report at around 9:00 pm. But what was even more surprising was the morning of July 12, when Thai police found the body of Alexandre Cazes. The 25-year-old had taken his own life in his cell.</p> <p>However, the investigators had what they wanted. They found incriminating evidence on his devices. They even found the password to his accounts in a text file. Using Cazes' laptop, they accessed AlphaBay's server and took control of the platform [5].</p>"},{"location":"cyber-threat-intelligence/historical-facts/#facebook-and-cambridge-analytica","title":"Facebook and Cambridge Analytica","text":"<p>Donald Trump\u2019s 2016 presidential campaign was deeply linked to a major privacy scandal involving the political consulting firm Cambridge Analytica, which collected data from up to 87 million Facebook profiles. The connection between the two originated when Steve Bannon, who would later become Trump\u2019s chief strategist, approached conservative donors Rebekah and Robert Mercer to finance the company. Bannon, serving as the firm\u2019s vice president, was the one who introduced Cambridge Analytica into the campaign team.</p> <p>Behind Cambridge Analytica was the SCL Group, a messaging and public relations agency that functioned as the firm\u2019s real operational structure. SCL Group used unsettling language to describe its capabilities, boasting of expertise in \u201cpsychological warfare\u201d and \u201cinfluence operations.\u201d Its business model was based on the premise that a sophisticated understanding of human psychology made it possible to identify and persuade individuals to accept the messages preferred by its clients.</p> <p>The method used to obtain this vast amount of information was through researcher Aleksandr Kogan, who created a quiz application within Facebook. The most critical aspect of this process was the exploitation of a legal loophole in Facebook\u2019s API, which allowed not only the collection of data from users who took the quiz, but also from all of their friends on the platform without their knowledge. Although Facebook prohibited the sale of data obtained through this method, Cambridge Analytica sold and used it anyway.</p> <p>In addition to data collection, it was reported that the firm\u2019s CEO, Alexander Nix, attempted to contact Julian Assange of WikiLeaks to obtain information about hacked emails from the Democratic National Committee. Mark Zuckerberg, Facebook\u2019s CEO, later admitted that the company had made mistakes. However, former employees pointed out that there was a constant internal tension within Facebook, where revenue-generating teams often won internal disputes over security teams seeking to protect users.</p> <p>Finally, the scandal caused Cambridge Analytica to lose multiple clients and face such severe negative publicity that the firm was forced to shut down its operations. This event cast doubt on Facebook\u2019s ability to protect user privacy, as it allowed a third party to design an application with the sole purpose of extracting data on a massive scale [6].</p>"},{"location":"cyber-threat-intelligence/historical-facts/#the-crime-solved-by-google-street-view","title":"The crime solved by Google Street View","text":"<p>In a small village in Spain (Tajueco), an image captured by a Google Street View car played an unexpected role in a police investigation. The photo, taken in October 2024, showed a man leaning over the trunk of a car while placing a large bundle\u2014suspiciously resembling a body\u2014inside it. That image reached the National Police, who used it as one of several clues to make progress in a disappearance case dating back to November 2023.</p> <p></p> <p>The investigation began when a family member reported the disappearance of a man of Cuban origin. Suspicious messages sent from his phone led investigators to believe that something was wrong, prompting the opening of a formal investigation.</p> <p>Thanks to the follow-up of the photo, authorities identified and arrested two individuals on November 12: the victim\u2019s partner and her former romantic partner, who were allegedly involved in the crime [7].</p>"},{"location":"cyber-threat-intelligence/references/","title":"References","text":"<p>[1] P. Chamoso Santos and M. A. Gonz\u00e1lez Arrieta, Tema 1: Introducci\u00f3n a la Inteligencia de Fuentes Abiertas (OSINT), Ciberinteligencia, M\u00e1ster Universitario en Ciberseguridad, Univ. de Salamanca, Curso 2025\u20132026.</p> <p>[2] ThreatConnect, Best Practices: Intelligence Requirements, ThreatConnect Knowledge Base, 04 Oct. 2023. [Online]. Available: https://knowledge.threatconnect.com/docs/best-practices-intelligence-requirements. Retrieved Jan. 10, 2026.</p> <p>[3] C. Reffgen and N. Felber, Admiralty Code for the Verification of Information, Enterprise Open Systems, 11 Mar. 2025. [Online]. Available: https://eosgmbh.com/en/admiralty-code-for-the-verification-of-information/. Retrieved Jan. 10, 2026.</p> <p>[4] The Intelligence Cycle (HTML), Central Intelligence Agency (CIA), 23 Mar. 2013. [Online]. Archived from the original (HTML) on 08 May 2020. Available: https://www.cia.gov/kids-page/6-12th-grade/who-we-are-what-we-do/the-intelligence-cycle.html. Retrieved Jan. 10, 2026.</p> <p>[5] M. Marlon, The Hunt for the King of the Dark Web, Vocal.Media: Criminal. [Online]. Available: https://vocal.media/criminal/the-hunt-for-the-king-of-the-dark-web. Retrieved Jan. 10, 2026.</p> <p>[6] A. Chang, The Facebook and Cambridge Analytica scandal, explained with a simple diagram, Vox, 23 Mar. 2018. [Online]. Available: https://www.vox.com/policy-and-politics/2018/3/23/17151916/facebook-cambridge-analytica-trump-diagram. Retrieved Jan. 10, 2026.</p> <p>[7] C. Prego, El coche de Google Maps capt\u00f3 a un hombre con un saco en un pueblo remoto de Soria. Ahora hay dos detenidos por asesinato, Xataka Magnet, 18\u00a0Dec.\u00a02024. [Online]. Available: https://www.xataka.com/magnet/coche-google-maps-retrato-a-hombre-saco-pueblo-soria-ahora-hay-dos-detenidos-asesinato. Retrieved Jan.\u00a010,\u00a02026.</p>"},{"location":"cyber-threat-intelligence/tools/","title":"Tools","text":""},{"location":"cyber-threat-intelligence/tools/#search-engines","title":"Search enginesGoogleBingDuckDuckGoTor Browser","text":"<p>Search engines provide broad access to indexed web content and are often the first entry point in OSINT investigations. When combined with advanced operators, they enable analysts to efficiently filter noise, uncover hidden resources, and identify relevant documents, metadata, and references across the open web.</p> Description General-purpose search engine widely used for OSINT investigations through advanced search operators. Access Web: https://www.google.com Key Features <ul><li>Web pages and documents</li><li>Cached content</li><li>Metadata via advanced operators (site:, filetype:, intitle:)</li></ul> License Free Description General search engine useful as an alternative data source and for cross-validation of results. Access Web: https://www.bing.com Key Features <ul><li>Web pages</li><li>Indexed documents</li><li>Image and video search results</li></ul> License Free Description Privacy-focused search engine with reduced personalization and tracking. Access Web: https://duckduckgo.com Key Features <ul><li>Web search results</li><li>Instant answers</li><li>Reduced user-based bias</li></ul> License Free Description Privacy-focused web browser designed to access the Tor network, enabling anonymous communication and access to .onion services while reducing tracking and fingerprinting risks. Access Web: https://www.torproject.org Key Features <ul><li>Routes traffic through the Tor network</li><li>Built-in protections against tracking and fingerprinting</li><li>Supports access to .onion services</li><li>Includes security levels and HTTPS-first defaults</li></ul> License Open Source (BSD 3-Clause License)"},{"location":"cyber-threat-intelligence/tools/#vertical-search-engines","title":"Vertical search enginesGoogle ImagesYandex Imagescrt.shShodanAhmia","text":"<p>Vertical search engines focus on a specific type of data or domain, offering deeper and more specialized results than general-purpose search engines. In OSINT, they are essential for reducing information overload and retrieving high-signal data such as exposed services, images, social media content, or historical web snapshots.</p> Description Image search engine with built-in reverse image search Access Web: https://images.google.com Key Features <ul><li>Reverse image search (upload image or paste URL)</li><li>Detection of visually similar images</li><li>Source webpages and image context</li></ul> License Free Description Image search engine particularly effective for reverse image searches. Access Web: https://yandex.com/images Key Features <ul><li>Visually similar images</li><li>Image sources</li><li>Alternate resolutions</li></ul> License Free Description Search engine for public TLS/SSL certificates. Access Web: https://crt.sh Key Features <ul><li>Issued certificates</li><li>Subdomain discovery</li><li>Certificate metadata</li></ul> License Free Description Internet-wide scanning service for inventorying exposed services and fingerprinting IoT and networked devices. Access Web: https://www.shodan.io Key Features <ul><li>Search and filter exposed services by banner, port, or vulnerability</li><li>Command-line interface and API for automation and integration</li><li>Historical data and monitoring of infrastructure changes</li></ul> License Freemium Description Search engine designed to index publicly accessible Tor (.onion) services, with a focus on transparency and abuse reduction. Commonly used for discovery and initial reconnaissance of dark web content. Access Web: https://ahmia.fi Key Features <ul><li>Indexes reachable .onion services</li><li>Filters known abusive or illegal content</li><li>Provides both clearnet and Tor-accessible interfaces</li><li>Useful for initial discovery and mapping of Tor sites</li></ul> License Open Source (BSD 3-Clause License)"},{"location":"cyber-threat-intelligence/tools/#web-archives","title":"Web archivesWayback MachineCDX APIWaybackpackCommon Crawlarchive.ph","text":"<p>Web archives preserve historical versions of websites and online content, allowing analysts to examine how information has changed over time. They are particularly valuable for attribution, timeline reconstruction, and recovering deleted or altered content that is no longer available on the live web.</p> Description Web archiving service providing historical snapshots of websites. Access Web: https://web.archive.org/ Key Features <ul><li>Archived versions of websites</li><li>Historical page content</li><li>Deleted or modified pages</li></ul> License Free Description API interface for querying Wayback Machine indexes programmatically. Access Repository: https://github.com/internetarchive/wayback/tree/master/wayback-cdx-server Key Features <ul><li>Snapshot metadata</li><li>Timestamped URLs</li><li>Change history</li></ul> License Free Category Web Archiving, Attribution, Historical Analysis Access Repository: https://github.com/jsvine/waybackpack Description Tool for downloading all archived versions of a website from the Wayback Machine, useful for attribution and historical analysis. Key Features <ul><li>Bulk download of archived snapshots of websites</li><li>Support for filtering by date and file type</li><li>Useful for tracking content changes over time</li></ul> License Open source (MIT) Description Open repository of large-scale web crawl data for bulk analysis and research. Access Web: https://commoncrawl.org Key Features <ul><li>HTML content</li><li>Web metadata</li><li>Large-scale historical datasets</li></ul> License Open source Description Web archiving service that captures snapshots of social media web pages, preserving content even if the original is removed. Access Web: https://archive.ph Key Features <ul><li>On-demand page snapshots</li><li>Permanent links to archived pages</li><li>Content preservation for deleted/modified social media</li></ul> License Free"},{"location":"cyber-threat-intelligence/tools/#sentiment-analysis","title":"Sentiment analysisBERT / RoBERTaFlairVADERTextBlob","text":"Description Advanced transformer-based NLP models used for high-accuracy sentiment analysis and contextual understanding of social media content. Access Web: https://pypi.org/project/fast-bert/ Key Features <ul><li>Deep contextual understanding</li><li>High sentiment classification accuracy</li><li>Handles sarcasm, negation, and complex language</li><li>Can be fine-tuned for SOCMINT-specific domains</li></ul> License Open Source Description NLP framework that provides efficient sentiment analysis using contextual string embeddings, suitable for real-time social media monitoring. Access Repository: https://github.com/flairNLP/flair Key Features <ul><li>Good balance between accuracy and performance</li><li>Fast inference compared to transformers</li><li>Easy integration into SOCMINT pipelines</li><li>Supports multiple languages</li></ul> License Open Source (MIT License) Description Lexicon and rule-based sentiment analysis tool optimized for social media language and short informal texts. Access Repository: https://github.com/cjhutto/vaderSentiment Key Features <ul><li>Optimized for social media text</li><li>Handles emojis, slang, and punctuation</li><li>Very fast processing speed</li><li>No training required</li></ul> License Open Source (MIT License) Description Simple NLP library providing basic sentiment analysis, mainly used for rapid prototyping and exploratory analysis. Access Web: https://textblob.readthedocs.io/en/dev/  Repository: https://github.com/sloria/TextBlob Key Features <ul><li>Very easy to use</li><li>Lightweight and fast</li><li>Good for educational or prototype SOCMINT projects</li></ul> License Open Source (MIT License)"},{"location":"cyber-threat-intelligence/tools/#government-records","title":"Government recordsdata.govdata.europa.eudatos.gob.esUK Companies HouseSEC EDGAR","text":"<p>Government records include publicly accessible databases and official publications released by state institutions. These sources provide authoritative data such as corporate registrations, legal notices, financial disclosures, and open datasets, making them critical for verification, attribution, and contextual analysis.</p> Description US government open data portal providing access to public datasets. Access Web: https://www.data.gov Key Features <ul><li>Government datasets</li><li>Statistics and reports</li><li>Geospatial data</li></ul> License Free Description European Union open data portal aggregating datasets from EU institutions and member states. Access Web: https://data.europa.eu Key Features <ul><li>EU datasets</li><li>Policy-related data</li><li>Economic and social indicators</li></ul> License Free Description Spanish national open data portal for public sector information. Access Web: https://datos.gob.es Key Features <ul><li>Administrative datasets</li><li>Geographical information</li><li>Public sector statistics</li></ul> License Free Description Official UK registry for company information. Access Web: https://www.gov.uk/government/organisations/companies-house Key Features <ul><li>Company registrations</li><li>Directors and shareholders</li><li>Financial filings</li></ul> License Free Description US SEC database of corporate financial filings. Access Web: https://www.sec.gov/edgar Key Features <ul><li>Annual and quarterly reports</li><li>Ownership disclosures</li><li>Regulatory filings</li></ul> License Free"},{"location":"cyber-threat-intelligence/tools/#domain-and-network","title":"Domain and networkWHOISRDAPNmap","text":"<p>Domain and network intelligence tools provide visibility into internet infrastructure, including domain ownership, IP address allocation, DNS records, and TLS certificates. They are fundamental for mapping digital assets, identifying relationships between entities, and supporting technical attribution in OSINT and cyber intelligence investigations.</p> Description Classic protocol to query information about domains and IPs, including registrant, creation/expiration dates, and DNS servers. Access CLI: <code>whois example.com</code>  Web: https://whois.domaintools.com Key Features <ul><li>Domain owner / registrant</li><li>Creation and expiration dates</li><li>DNS servers and administrative contacts</li></ul> License Open source Description Modern protocol that replaces WHOIS, providing standardized JSON responses; ideal for automation and structured analysis of domains and IPs. Access CLI: <code>curl https://rdap.org/domain/example.com</code>  Web: https://rdap.org Key Features <ul><li>Domain owner / registrant</li><li>Creation, update, and expiration dates</li><li>DNS servers, contacts, and legal notes</li></ul> License Open source Description Network scanning and reconnaissance tool used to discover hosts, open ports, services, and operating systems. Access CLI: <code>nmap target</code>  Web: https://nmap.org  Repository: https://svn.nmap.org/ Key Features <ul><li>Host discovery and port scanning</li><li>Service and version detection</li><li>OS fingerprinting and scripting engine (NSE)</li></ul> License Open source"},{"location":"cyber-threat-intelligence/tools/#media-monitoring","title":"Media monitoringGoogle NewsGDELT 2.0BRAND24","text":"<p>Media monitoring tools aggregate and analyze digital news sources at local, national, and global levels. They enable continuous tracking of events, narratives, and trends, and support large-scale analysis of media coverage, making them valuable for situational awareness and strategic intelligence.</p> Description News aggregation platform with advanced search and filtering options. Access Web: https://news.google.com Key Features <ul><li>News articles</li><li>Source attribution</li><li>Timeline-based results</li></ul> License Free Description Global database for monitoring worldwide news media and events. Access Web: https://www.gdeltproject.org Key Features <ul><li>Global news coverage</li><li>Event metadata</li><li>Geopolitical indicators</li></ul> License Free <p>Media monitoring tools aggregate and analyze digital news sources at local, national, and global levels. They enable continuous tracking of events, narratives, and trends, and support large-scale analysis of media coverage, making them valuable for situational awareness and strategic intelligence.</p> Description Social listening and online brand reputation management tool that tracks mentions across platforms. Access Web: https://brand24.com Key Features <ul><li>Real-time social mentions tracking</li><li>Sentiment analysis</li><li>Influencer identification</li></ul> License Commercial (SaaS)"},{"location":"cyber-threat-intelligence/tools/#geoint","title":"GEOINTSentinel-2MarineTraffic","text":"<p>GEOINT tools leverage geospatial data such as satellite imagery, sensor feeds, and location-based tracking systems. These sources allow analysts to verify locations, monitor physical movements, and correlate events in the real world with digital information.</p> Description Earth observation satellite providing free multispectral imagery. Access Web: https://sentinel.esa.int Key Features <ul><li>Satellite imagery</li><li>Environmental monitoring data</li><li>Temporal change detection</li></ul> License Free Description AIS-based vessel tracking platform. Access Web: https://www.marinetraffic.com Key Features <ul><li>Ship positions</li><li>Vessel metadata</li><li>Historical movement tracks</li></ul> License Freemium"},{"location":"cyber-threat-intelligence/tools/#data-leaks","title":"Data leaksPastebin","text":"<p>Data leak sources include platforms where raw text, databases, or credentials are publicly shared, intentionally or unintentionally. In OSINT and CTI, they are commonly used to identify exposed information, monitor breach activity, and detect early indicators of compromise or criminal activity.</p> Description Website used to publish text content, often associated with leaks or dumps. Access Web: https://pastebin.com Key Features <ul><li>Leaked credentials</li><li>Configuration files</li><li>Source code snippets</li></ul> License Free / Freemium"},{"location":"cyber-threat-intelligence/tools/#people-search","title":"People searchRecon-ngMaltegoSpiderFoottheHarvester","text":"<p>People search tools focus on identifying and correlating information related to individuals across public sources. They support the discovery of digital footprints, social connections, and publicly available personal data, and are often used in background research and attribution workflows.</p> Description Modular Metasploit-style framework for OSINT; ideal for large-scale scripting. Access Repository: https://github.com/lanmaster53/recon-ng Key Features <ul><li>Modular architecture with multiple reconnaissance modules</li><li>Automated data collection from public sources and APIs</li><li>Workspace-based data management and export capabilities</li></ul> License Open source (GPL 3.0) Description Graph-based visualization and pivoting between entities using hundreds of built-in transforms, widely used in SOCMINT and CTI investigations. Access Web: https://www.maltego.com Key Features <ul><li>Interactive graph visualization for complex relationship analysis</li><li>Extensive library of transforms for domains, people, organizations, and infrastructure</li><li>Pivoting across multiple data sources from a single entity</li></ul> License Free for non-commercial use (Community Edition) Description Automated OSINT collection framework with 200+ modules for domains, IPs, and digital identities; integrates with services such as Shodan and Have I Been Pwned. Access Repository: https://github.com/smicallef/spiderfoot Key Features <ul><li>Large modular scanning engine with extensive data source coverage</li><li>Automated correlation of results across multiple sources</li><li>Integration with external threat intelligence platforms and APIs</li></ul> License Open source (MIT) Description Fast enumeration tool for emails, subdomains, hosts, and open ports using search engines and public APIs. Access Repository: https://github.com/laramies/theHarvester Key Features <ul><li>Rapid discovery of email addresses and subdomains</li><li>Support for multiple search engines and data sources</li><li>Lightweight and easy integration into reconnaissance workflows</li></ul> License Open source"},{"location":"cyber-threat-intelligence/tools/#metadata-analysis","title":"Metadata analysisExifToolMediaInfoFFmpeg / FFprobeMAT2XnView MP","text":"Description De facto standard for reading, writing, and normalizing EXIF, XMP, and IPTC metadata across a wide range of file formats. Access Website: https://exiftool.org/  Repository: https://github.com/exiftool/exiftool Key Features <ul><li>Supports hundreds of file formats</li><li>Read, write, and delete metadata</li><li>Highly scriptable and automation-friendly</li><li>Widely used in digital forensics and OSINT</li></ul> License Open Source (GPL 3.0) Description Technical analysis tool for audio and video files, providing detailed information about codecs, bitrates, containers, and timestamps. Access Website: https://mediaarea.net/en/MediaInfo  Repository: https://github.com/MediaArea/MediaInfo Key Features <ul><li>Detailed codec and container inspection</li><li>Supports audio, video, and subtitle streams</li><li>CLI and GUI versions available</li><li>Commonly used in media forensics</li></ul> License Open Source (BSD 2-Clause License) Description Comprehensive multimedia framework for inspecting, processing, and extracting metadata, keyframes, and media streams. Access Website: https://ffmpeg.org/  Repository: https://git.ffmpeg.org/ffmpeg.git Key Features <ul><li>Extract and inspect detailed media metadata</li><li>Keyframe and stream analysis with FFprobe</li><li>Supports virtually all audio/video formats</li><li>Powerful CLI for forensic workflows</li></ul> License Open Source (LGPL and GPL) Description Tool designed to detect and remove metadata from files before sharing, helping to prevent unintentional information disclosure. Access Repository: https://github.com/tpet/mat2 Key Features <ul><li>Removes metadata from images, documents, audio, and video</li><li>Focus on privacy and operational security</li><li>CLI and GUI versions available</li><li>Used by journalists and activists</li></ul> License Open Source (LGPL 3.0) Description Cross-platform media viewer with basic EXIF/IPTC metadata viewing and editing capabilities. Access Website: https://www.xnview.com/en/xnviewmp/ Key Features <ul><li>View and edit basic EXIF/IPTC metadata</li><li>Supports a large number of image formats</li><li>Batch processing capabilities</li><li>User-friendly graphical interface</li></ul> License Freemium"},{"location":"cyber-threat-intelligence/tools/#general-purpose","title":"General purposeLampyre OSINT StudioOSINT CombineOSINT Framework","text":"<p>General-purpose OSINT tools provide flexible functionality that can be applied across multiple investigative domains. Rather than targeting a single data type, they act as frameworks or aggregation platforms that help structure, automate, or correlate information from diverse open sources.</p> Description OSINT analysis platform for mixed datasets (financial, telecommunications, and social networks) using predefined query templates. Access Web: https://lampyre.io Key Features <ul><li>Correlation of heterogeneous data sources in a single workspace</li><li>Predefined analytical templates for investigations</li><li>Advanced visualization and link analysis capabilities</li></ul> License Freemium Description AI-powered SaaS platform for prioritizing alerts and deduplicating findings from multiple OSINT and CTI sources. Access Web: https://www.osintcombine.com Key Features <ul><li>Automated correlation and deduplication of OSINT data</li><li>AI-assisted prioritization of alerts and findings</li><li>Centralized dashboard for multi-source intelligence analysis</li></ul> License Commercial (SaaS) Description Web-based framework that organizes a large collection of OSINT tools and resources by category, helping analysts find relevant tools for different investigative tasks. It presents links in a structured, interactive layout. Access Web: https://osintframework.com  Repository: https://github.com/lockfale/osint-framework Key Features <ul><li>Comprehensive directory of free and paid OSINT tools</li><li>Categorized by data type and investigative use</li><li>Interactive map/tree structure for navigation</li><li>Links to third-party tools for deep dives</li></ul> License Open source (MIT license)"},{"location":"cyber-threat-intelligence/dark-web/","title":"Dark Web","text":""},{"location":"cyber-threat-intelligence/dark-web/#concepts","title":"Concepts","text":"<ul> <li> <p>Surface Web: The visible and indexed part of the Internet, accessible through conventional search engines (Google, Bing, etc.).</p> </li> <li> <p>Deep Web: The portion of the Internet not indexed by standard search engines. Its content is usually behind forms, paywalls, or authentication (login), or is dynamically generated and not exposed to crawlers. Accessing the deep web does not require special software; typically, legitimate credentials or knowing the exact URL are enough. It is mostly legitimate and necessary for the daily operations of organizations and services.</p> </li> <li> <p>Dark Web: An intentionally hidden subset of the deep web, accessible through specific networks/software (e.g., Tor, I2P, Freenet). Its services do not use public DNS nor are they indexed by traditional search engines. The dark web provides enhanced anonymity for users and operators, making it attractive for both legitimate uses (privacy, freedom of expression, journalism) and illicit activities.</p> </li> </ul> <p></p>"},{"location":"cyber-threat-intelligence/dark-web/#access-networks","title":"Access networks","text":""},{"location":"cyber-threat-intelligence/dark-web/#tor","title":"Tor","text":"<p>Tor (The Onion Router) is a network that hides your IP address and the location of the sites you connect to. It is used for privacy, to bypass censorship, and to access hidden services with <code>.onion</code> addresses. The typical way to access Tor is through Tor Browser, which is pre-configured to minimize the browser\u2019s digital footprint.  </p> <p>Tor creates an encrypted 3-hop circuit (nodes) to reach the Internet. In <code>.onion</code> services (also called hidden services), there is no exit node to the Internet: the client and service communicate entirely within Tor through intermediate nodes, providing anonymity to both ends. Current <code>.onion</code> addresses (v3) are 56-character strings derived from a public key; if the key changes, the address changes as well.  </p> <p>When Tor is blocked, it can be started using bridges (unlisted entry nodes) and pluggable transports (e.g., obfs4, snowflake) that obfuscate traffic. Applications can use Tor via SOCKS5 (e.g., 127.0.0.1:9050) or utilities such as torsocks.</p> <p>Tor + VPN</p> <p>Tor alone is usually sufficient. A VPN \u2192 Tor (\"Tor over VPN\") can hide from your ISP (internet service provider) that you are using Tor, but it does not improve anonymity within the network; evaluate the VPN\u2019s policies. Chaining Tor \u2192 VPN (\"VPN over Tor\") is more complex and uncommon.</p>"},{"location":"cyber-threat-intelligence/dark-web/#i2p","title":"I2P","text":"<p>I2P (The Invisible Internet Project) is a network that provides an abstraction layer for communication between computers, allowing the creation of network tools and applications with strong anonymity. It is a network focused on internal services (called eepsites) and anonymous messaging. Unlike Tor, its priority is not browsing the public web, but communicating within I2P with low exposure.  </p> <p>I2P routes traffic through unidirectional tunnels (one for sending and one for receiving) and encapsulates messages using garlic routing (multiple messages in one). The network maintains a distributed database (netDb) to discover destinations; some addresses use the base32 format <code>.b32.i2p</code>. Latency is usually higher than Tor for regular web browsing, but it is suitable for persistent internal services.</p>"},{"location":"cyber-threat-intelligence/dark-web/#freenet","title":"Freenet","text":"<p>Freenet is a P2P network focused on publishing and storing content in a censorship-resistant manner. Instead of \"browsing\" servers, data blocks (chunks) are retrieved from nodes distributed across the network.  </p> <p>Content is addressed using keys: CHK (immutable content) and SSK/USK (allow for updatable publications). Routing is probabilistic with a distributed cache; it provides persistence and censorship resistance at the cost of higher latency.</p>"},{"location":"cyber-threat-intelligence/dark-web/#recommendations","title":"Recommendations","text":"<p>Do:</p> <ul> <li> <p>Use live systems or dedicated VMs: A live operating system (live OS) runs directly from a USB or DVD without installing anything on the host computer, leaving no trace on the personal machine. Using Tails (a live OS with Tor enabled by default) or dedicated VMs (e.g., Whonix) separates your research environment from your personal device, improving security and privacy.</p> </li> <li> <p>Segmentation in Qubes/VMs: In more advanced setups, isolate tasks (browsing, downloading, file analysis) in separate disposable VMs.</p> </li> <li> <p>Research accounts and profiles: Maintain separate identities with no link to real profiles, and rotate them periodically when needed.</p> </li> <li> <p>Anti-exfiltration tools: Disable automatic mounting of external USBs and block WebRTC. These measures prevent accidental data leaks that could reveal your real IP address, device information, or other sensitive information to websites or observers on the network.</p> </li> <li> <p>DNS leaks: Make sure that all DNS queries go through the anonymous network (Tor, VPN, proxy) and not directly through your Internet Service Provider. To achieve this, it is recommended to replace your ISP\u2019s DNS with Google DNS or Cloudflare DNS.</p> </li> <li> <p>Use the highest security level compatible with your task: Disable active functions when not needed (JavaScript, multimedia).  </p> </li> <li> <p>Verify downloads: Check signatures/PGP or hashes, and open files offline in disposable machines.  </p> </li> <li> <p>Double-check the exact domain address: Phishing clones exist, so confirm you are accessing the correct domain or <code>.onion</code> address.</p> </li> </ul> <p>Don't:</p> <ul> <li> <p>Use personal accounts: Log in with personal accounts or reuse real aliases.  </p> </li> <li> <p>Modify the browser: Resize windows, install browser extensions, or use plugins (Flash, Java, etc.).  </p> </li> <li> <p>Unsafe document handling: Download documents and open them online; they may leak your IP or telemetry data.  </p> </li> <li> <p>Use high-exposure protocols: Use torrents or protocols that expose your real IP address.  </p> </li> <li> <p>Unauthorized interactions: Interact (purchase, post, offer services) unless you have explicit authorization and a clear legal framework.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/dark-web/#current-trends","title":"Current trends","text":"<p>After shutdowns and exit scams, many communities frequently migrate between <code>.onion</code> domains and, in parallel, to invitation-only forums on the clear web or to public channels on encrypted messaging platforms (e.g., Telegram). This fragments the conversation, shortens lifecycle spans, and requires continuous monitoring of new gathering points.</p> <p>The market for stolen credentials and infostealer logs (cookies, tokens, sessions) continues to grow due to their usefulness in bypassing MFA, hijacking sessions, and facilitating fraud. The supply of combos (email + password) and sector- or country-segmented packages is increasing.</p> <p>Alongside Bitcoin, there is increasing use of privacy-focused cryptocurrencies (e.g., Monero) and mixers. Operators rotate wallets and publish instructions for \u201csecure\u201d payments; at the same time, open-source transaction tracing is becoming widespread for financial intelligence.</p> <p>Longer v3 .onion domains, frequent service rotation, highly convincing phishing clones, and more aggressive anti-crawling protections (rate limits, proof-of-work, graylists). Passive observation and responsible archiving are increasingly favored over intrusive collection methods.</p>"},{"location":"cyber-threat-intelligence/dark-web/types-of-sites/","title":"Types of sites","text":"<p>The Dark Web hosts a variety of services, ranging from legitimate privacy-focused spaces to illicit environments. Understanding how they are organized and what signals to watch for helps plan monitoring safely and without engaging in prohibited activities.</p>"},{"location":"cyber-threat-intelligence/dark-web/types-of-sites/#directories","title":"Directories","text":"<ul> <li> <p>Indexes: List services and allow keyword queries. They are often incomplete and sometimes outdated.</p> </li> <li> <p>Risk of clones: Popular sites often have fake domains that imitate their appearance to steal funds or credentials. Always verify the PGP key or the operator\u2019s official announcement when available.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/dark-web/types-of-sites/#forums-and-communities","title":"Forums and communities","text":"<ul> <li> <p>Topics: Security and anonymity, leaks, fraud, peer-to-peer trading, technical manuals, and general discussions under pseudonyms.</p> </li> <li> <p>Structure: Registration by invitation or captchas, reputation-based hierarchies, moderated threads.</p> </li> <li> <p>Signals to watch: Forum creation date, actual activity (users per 24h), posting rules, history of closures or migrations.</p> </li> <li> <p>Note: Passive access for analysis is subject to forum rules; do not participate or request/share illegal material.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/dark-web/types-of-sites/#marketplaces","title":"Marketplaces","text":"<ul> <li> <p>Model: Catalogs with sellers, ratings, shopping carts, and cryptocurrency payments. Many use escrow (custody) and internal messaging with PGP. Escrow is an intermediary mechanism in which a neutral third party holds a payment or asset until the conditions agreed upon by the parties are fulfilled.</p> </li> <li> <p>Common categories: Stolen data, forged documents, intrusion tools, substances, cards/credentials, cash-out or drop services.</p> </li> <li> <p>Volatility: Closures due to operator exit scams, police seizures, and frequent migrations to new .onion domains.</p> </li> <li> <p>Risks: Phishing, exit scams, and malware in downloads. Any interaction may be illegal; professional analysis is limited to observation, evidence preservation, and reporting.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/dark-web/types-of-sites/#leak-sites-and-secure-dropboxes","title":"Leak sites and secure dropboxes","text":"<ul> <li> <p>Ransomware group leak sites: Pages where data samples are published to pressure victims. They usually list the organization, date, and \"proof identifiers\". Lockbit pages are an example of a Dark Web site where data stolen by the Lockbit ransomware can be obtained.</p> </li> <li> <p>Secure dropboxes for legitimate leaks: Projects like SecureDrop and GlobaLeaks provide anonymous channels for journalists and NGOs; these are legitimate uses focused on protecting sources.</p> </li> <li> <p>Consideration: Never download or redistribute personal data; work with partial screenshots and report through established institutional channels.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/dark-web/types-of-sites/#communication-and-utility-services","title":"Communication and utility services","text":"<ul> <li> <p>.onion email and messaging: Privacy-focused email and instant messaging providers, using PGP/OTR.</p> </li> <li> <p>Pastebins and wikis: Sharing of text, manuals, how-tos, and listings; useful for tracking narratives and operator announcements.</p> </li> <li> <p>Mirrors and status pages: Sites that publish official mirrors and service statuses to mitigate takedowns.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/dark-web/types-of-sites/#observable-technical-infrastructure","title":"Observable Technical Infrastructure","text":"<ul> <li> <p>Panels and dashboards: Occasionally, administrative interfaces are accidentally exposed (brief time windows).</p> </li> <li> <p>C2 and beacons: Some investigations document traces of command-and-control infrastructure; identifying them requires extreme caution and coordination with specialized teams.</p> </li> <li> <p>Best practices: Do not interact; limit activities to observation and reporting to the appropriate security channels.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/fundamentals/","title":"Fundamentals","text":""},{"location":"cyber-threat-intelligence/fundamentals/#definition-of-threat-intelligence","title":"Definition of threat intelligence","text":"<p>A cyberthreat is understood as the possibility of carrying out malicious actions that affect the confidentiality, integrity, and/or availability of the resources of a computer system. Therefore, threat intelligence refers to the knowledge, skills, and experience-based information about cyberthreats, aimed at helping to mitigate potential attacks and harmful events that occur in cyberspace.</p> <p>In the field of cybersecurity, threat intelligence plays a crucial role in anticipating potential attacks. Threat intelligence provides context, such as who is attacking us, what their motivation and capabilities are, and which indicators of compromise allow us to detect the attacks. This context helps organizations make faster, more informed security decisions and shift their approach from reactive to proactive in combating attacks.</p>"},{"location":"cyber-threat-intelligence/fundamentals/#types-of-threat-intelligence","title":"Types of threat intelligence","text":"<p>Regarding the types of threat intelligence that exist, various sources only distinguish between operational intelligence and strategic intelligence. Others also include tactical intelligence and even technical intelligence.</p>"},{"location":"cyber-threat-intelligence/fundamentals/#strategic-intelligence","title":"Strategic intelligence","text":"<p>Strategic threat intelligence provides a broad view of an organization's threat landscape. It is designed to inform high-level decisions made by executives and other decision-makers within an organization, which means its content is usually less technical and is presented through reports or briefings.</p> <p>The most common information sources for strategic threat intelligence include:</p> <ul> <li> <p>Policy documents from nation-states or non-governmental organizations (NGOs).</p> </li> <li> <p>News from local and national media, industry- and topic-specific publications, or other subject-matter experts.</p> </li> <li> <p>Books, research reports, and other content produced by security organizations.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/fundamentals/#tactical-intelligence","title":"Tactical intelligence","text":"<p>Tactical threat intelligence describes the tactics, techniques, and procedures (TTPs) of threat actors. It is intended to help defenders understand, in specific terms, how their organization could be attacked and the best ways to defend against or mitigate those attacks. It usually includes technical context and is used by personnel directly involved in defending an organization, such as system architects, administrators, and security staff.</p> <p>Its sources include information about attack vectors, the tools and infrastructure that attackers are using, including details on which vulnerabilities are being targeted and which exploits attackers are leveraging, as well as the strategies and tools they may be using to evade or delay detection.</p>"},{"location":"cyber-threat-intelligence/fundamentals/#technical-intelligence","title":"Technical intelligence","text":"<p>Technical intelligence refers to detailed, actionable information about cyber threats, including specific indicators of compromise (IOCs), attack vectors, tools, tactics, techniques, and procedures (TTPs) used by threat actors. It is primarily used by security teams to detect, prevent, and respond to cyberattacks in real time. Technical intelligence often comes from threat data feeds, malware analysis, logs, and other technical sources that provide granular, operational-level insights.</p>"},{"location":"cyber-threat-intelligence/fundamentals/#operative-intelligence","title":"Operative intelligence","text":"<p>Operational intelligence is knowledge about cyberattacks, events, or campaigns. It provides specialized information that helps incident response teams understand the nature, intent, and timing of specific attacks.</p> <p>Since it usually includes technical information \u2014such as which attack vector is being used, which vulnerabilities are being exploited, or which command-and-control domains are being employed\u2014 this type of intelligence is also referred to as technical threat intelligence. A common source of technical information is threat data feeds, which typically focus on a single type of indicator, such as malware hashes or suspicious domains.</p>"},{"location":"cyber-threat-intelligence/fundamentals/#indicators","title":"Indicators","text":"<p>It is important to understand the difference between the two most important types of threat intelligence indicators; indicators of compromise and indicators of attack, when a company adopts and develops an intelligence program.</p>"},{"location":"cyber-threat-intelligence/fundamentals/#indicators-of-compromise","title":"Indicators of compromise","text":"<p>An indicator of compromise (IoC) is usually described in the forensic world as evidence that indicates a network\u2019s security has been breached. Researchers typically collect this data after being notified of a suspected incident. Ideally, this information is gathered to create \u201csmarter\u201d tools that can detect and mitigate attacks.</p> <p>The most common IoCs are, for example:</p> <ul> <li> <p>Suspicious or known hostile domain or IP.</p> </li> <li> <p>Checksum of a suspicious or known hostile file (e.g., MD5, SHA256).</p> </li> <li> <p>Rules or signatures to detect suspicious or known data, such as antivirus and IDS signatures.</p> </li> <li> <p>Data related to the potential exploitation of a vulnerability.</p> </li> <li> <p>Tactics, Techniques, and Procedures (TTPs) associated with hostile events, such as an unauthorized instance of Mimikatz on an endpoint.</p> </li> </ul> <p>Indicators of compromise can be classified into three categories:</p> <ul> <li> <p>Atomic: Those that cannot be divided into smaller parts and retain their meaning in the context of an intrusion (e.g., IP address, URL, email address, registry key, file path, vulnerability identifiers).</p> </li> <li> <p>Computed: Those derived from data related to an incident (e.g., regular expressions, file hash values).</p> </li> <li> <p>Behavioral: Those that result from grouping atomic and computed indicators, subject to qualification by quantity and logical combinatorial possibilities (e.g., the intruder initially uses a backdoor that employs [port], generating network traffic matching [regular expression] and [connection frequency] to [IP address/URL], with this backdoor being replaced, once the connection with the C2 server is established, by another executable with hash value [MD5 hash]).</p> </li> </ul> <p>The three most commonly shared indicators (hashes, IP addresses, and domain names) are also the easiest to evade, which limits their usefulness. For an attacker, it is trivial to modify a hash\u2014from compilation to execution\u2014change an IP address used as a C2 or exfiltration server, or alter domain names with minimal effort. Thus, a threat actor with basic capabilities can evade detection based on these types of indicators. However, when it comes to behavioral indicators with TTPs, modifying them is more difficult for an actor. Therefore, if we can detect these modus operandi, our success in identifying compromises increases.</p> <p>So, if atomic and computed indicators are not the most useful, why are they the most commonly used and shared? The answer is simple: they can be automatically ingested into security tools, providing immediate results. Identifying TTPs, in many cases, requires establishing relationships between security events; these relationships are often temporal but can also be tied to dependencies between activities, for example.</p> <p>In summary, we share the intelligence that is easiest to use, but not the best. To detect advanced threat activities, we need to share the most valuable intelligence, and to achieve this, that intelligence must be automatically processable across all relevant environments, ideally following a standard.</p>"},{"location":"cyber-threat-intelligence/fundamentals/#indicators-of-attack","title":"Indicators of attack","text":"<p>Indicators of attack (IoA) focus on detecting the intent of what an attacker is trying to achieve, regardless of the malware or exploit used in an attack. Like AV signatures, an IOC-based detection approach cannot detect the growing threats of malware-less intrusions and zero-day exploits. As a result, next-generation security solutions are moving toward an IoA-based approach.</p> <p>Indicators of attack focus more on the why and the intent of an actor. In many ways, they represent a more strategic view of an actor\u2019s or group\u2019s techniques, tactics, and procedures. When properly placed within a more mature intelligence program, IoAs can genuinely identify proactive strategies for detecting and defending against new, unknown threats.</p>"},{"location":"cyber-threat-intelligence/fundamentals/intelligence-cycle/","title":"Intelligence cycle","text":"<p>The intelligence cycle is an idealized model of how intelligence is processed in civilian and military intelligence agencies, and law enforcement organizations. It is a closed path consisting of repeating nodes, which (if followed) will result in finished intelligence. The stages of the intelligence cycle include the issuance of requirements by decision makers, collection, processing, analysis, and publication (e.g., dissemination) of intelligence [4].</p>"},{"location":"cyber-threat-intelligence/fundamentals/intelligence-cycle/#concepts","title":"Concepts","text":"<p>To explain the phases of this cycle, we must first define the following terms:</p> <ul> <li> <p>Data: Collection of discrete values that convey information, describing quantity, quality, facts, statistics, other basic units of meaning, or simply sequences of symbols that can be interpreted later. A datum is an individual value within a data set. Data are usually organized into structures, such as tables, which provide additional context and meaning, and in turn can be used as data within larger structures.</p> </li> <li> <p>Information: Term used to refer to a set of processed data that, when combined, allow answering a simple question. Information is the output of processed data that contains meaning and context. Therefore, information can be considered as the knowledge generated when a set of data providing different facts about an event are combined or interconnected to provide an overview of that event or to answer a question.</p> </li> <li> <p>Intelligence: It is the product resulting from the collection, processing, and analysis of data and information about threats, which provides contextualized, timely, and actionable knowledge to identify, anticipate, and mitigate risks in cyberspace.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/fundamentals/intelligence-cycle/#phases","title":"Phases","text":"<p>The intelligence cycle is composed of these phases:</p> <ol> <li> <p>Direction:   Intelligence requirements are determined by a decision maker to meet their objectives.</p> </li> <li> <p>Collection:   In response to requirements, an intelligence staff develops an intelligence collection plan applying available sources and methods and seeking intelligence from other agencies. Collection includes inputs from several intelligence gathering disciplines, such as HUMINT (human intelligence), IMINT (imagery intelligence), ELINT (electronic intelligence), SIGINT (signals intelligence), OSINT (open source, or publicly available intelligence), data from the Dark Web, etc.</p> </li> <li> <p>Processing and exploitation:   Once the collection plan is executed and the data arrives, it is processed for exploitation. This involves translation of raw intelligence materials from a foreign language, evaluation of relevance and reliability (e.g., with the Admiralty Code [3]), and collation of the raw data in preparation for exploitation.</p> </li> <li> <p>Analysis:   Analysis establishes the significance and implications of processed intelligence. It integrates information by combining disparate pieces of data to identify collateral information and patterns, then interprets the significance of any newly developed knowledge.</p> </li> <li> <p>Dissemination:   Finished intelligence products take many forms depending on the needs of the decision maker and reporting requirements.</p> </li> </ol> <p>The intelligence cycle is a closed loop; feedback is received from the decision maker and revised requirements issued.</p> <pre><code>graph TD\n    %% Nodos (Uso de comillas para evitar errores de sintaxis)\n    Phase1[\"&lt;b&gt;1. Direction&lt;/b&gt;\"]\n    Phase2[\"&lt;b&gt;2. Collection&lt;/b&gt;\"]\n    Phase3[\"&lt;b&gt;3. Processing and exploitation&lt;/b&gt;\"]\n    Phase4[\"&lt;b&gt;4. Analysis&lt;/b&gt;\"]\n    Phase5[\"&lt;b&gt;5. Dissemination&lt;/b&gt;\"]\n\n    %% Conexiones\n    Phase1 --&gt;|Define needs| Phase2\n    Phase2 --&gt;|Raw data| Phase3\n    Phase3 --&gt;|Processed information| Phase4\n    Phase4 --&gt;|Intelligence| Phase5\n\n    %% Bucle de Retroalimentaci\u00f3n\n    Phase5 -.-&gt;|Feedback and &lt;br/&gt;revised requirements| Phase1</code></pre>"},{"location":"cyber-threat-intelligence/osint/","title":"OSINT","text":"<p>Open-Source Intelligence (OSINT) is the discipline that identifies, collects, processes, analyzes, and disseminates information from publicly accessible sources\u2014such as websites, social media, news media, government databases, Internet technical data, satellite imagery, and others\u2014in order to respond to a specific intelligence requirement [1].</p>"},{"location":"cyber-threat-intelligence/osint/#intelligence-requirement","title":"Intelligence requirement","text":"<p>Therefore, an intelligence requirement is the defining element that triggers the cyber intelligence process [2]. Examples of how to transform a problem into a intelligence requirement could be the following ones [1]:</p> Problem Intelligence Requirement Suspecting that an organization or individual is carrying out malicious activities Determine if this person is associated with a terrorist group A company needs information about the risks of operating in a specific country or region Assess the political and economic stability of a country to consider an investment Tracking or solving a crime Locate the whereabouts of a fugitive Keeping track of a competitor or a target organization Monitor the activities of a competing company Ensuring the accuracy of media reports or political claims Verify the authenticity of a news story or statement"},{"location":"cyber-threat-intelligence/osint/#historical-evolution","title":"Historical evolution","text":"<ul> <li> <p>1941\u20131980 (Pre-digital era):   The U.S. Foreign Broadcast Monitoring Service (FBIS) monitored foreign radio broadcasts during World War II; this practice institutionalized the use of open sources to support strategic decision-making.</p> </li> <li> <p>1990s\u20132000s:   The expansion of the Internet multiplied open data repositories, and the first open data portals appeared. OSINT was still considered a complement to SIGINT/HUMINT.</p> </li> <li> <p>2010\u20132020:   The explosion of social media, mobile broadband, and open government data elevated OSINT as a key discipline in investigative journalism (e.g., Arab Spring or Panama Papers leaks).</p> </li> <li> <p>2022\u2013present:   The war in Ukraine and the popularization of generative AI have made OSINT a primary source of real-time situational awareness, capable of verifying military movements via satellite images and geolocated videos shared by the community.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/osint/#current-situation","title":"Current situation","text":"<p>Nowadays, the scope and relevance of OSINT have been amplified, mainly due to these three factors:</p> <ol> <li> <p>Data proliferation: Every minute, millions of posts, records, and transactions are uploaded; even commercial satellites offer revisit times of less than 24 hours over most of the planet.</p> </li> <li> <p>AI and automation tools: Computer vision algorithms, natural language processing, and link analysis allow filtering noise and detecting hidden patterns.</p> </li> <li> <p>Regulatory maturity: Frameworks such as GDPR or the EU AI Act require the integration of privacy and transparency, professionalizing the discipline.</p> </li> </ol>"},{"location":"cyber-threat-intelligence/osint/#use-cases","title":"Use cases","text":"<ul> <li> <p>Conflict verification: Analysis of satellite images and videos to confirm movements and damages almost in real time.</p> </li> <li> <p>Disinformation detection: Monitoring hashtags and coordinated bot networks. Increasingly challenging with generative AI (deepfakes).</p> </li> <li> <p>Supply chain risks: Cross-referencing customs, patents, and corporate records to detect business links and potential sanctions violations.</p> </li> <li> <p>Cybercrime investigation: Correlation of domains, TLS certificates, and forums for technical and contextual attribution of malware, phishing, or ransomware campaigns.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/osint/limitations-and-ethics/","title":"Limitations and ethics","text":""},{"location":"cyber-threat-intelligence/osint/limitations-and-ethics/#tecnical-challenges","title":"Tecnical challenges","text":"<ul> <li> <p>Anti-scraping measures: Many platforms implement rate limits, CAPTCHAs, dynamic rendering, and bot detection. Changes in the DOM and APIs frequently break automation. It is necessary to design data collection processes that are resilient, log selector versions, and maintain alternatives such as official APIs or web archives.</p> </li> <li> <p>Information overload and noise: The volume of data and duplication make it difficult to identify relevant signals. Effective handling requires applying filters, deduplication, sampling, and prioritization aligned with Intelligence Requirements (IR).</p> </li> <li> <p>Synthetic content (deepfakes/generated text): Images, audio, and text generated by AI are increasingly common. Analysts must verify origin (when available, using metadata or provenance standards such as C2PA), perform basic forensic checks (visual, spatial, or temporal inconsistencies), and corroborate information using methods like the Rule of Two or temporal/geospatial triangulation.</p> </li> <li> <p>Volatility and disappearance of historical data: Retention policies, content deletion, and ephemeral formats (stories, streams) reduce traceability. Captures should be timestamped, evidence hashed, archives (Wayback or institutional archives) consulted, and chain-of-custody procedures followed.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/osint/limitations-and-ethics/#privacy-legality-and-compliance","title":"Privacy, legality, and compliance","text":"<ul> <li> <p>Legal basis and minimization: Collect only what is necessary for a legitimate purpose (principles of lawfulness, purpose limitation, and data minimization). Avoid special categories of data unless clearly permitted by law.</p> </li> <li> <p>Terms of service and unauthorized access: Respect platform ToS (terms of service) and do not bypass technical controls (no bypassing of paywalls, gating, or authentication).</p> </li> <li> <p>Jurisdiction and international transfer: Consider where data is stored or processed and the applicable regulatory regimes (e.g., GDPR/NIS2 in the EU). Document transfer bases when relevant.</p> </li> <li> <p>Third-party rights: Avoid doxxing, harassment, or unnecessary exposure of non-target individuals. Evaluate proportionality before including personal data in intelligence products.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/osint/limitations-and-ethics/#analyst-operations-security","title":"Analyst operations security","text":"<ul> <li> <p>Identity separation: Use isolated accounts and research environments (virtual machines, depersonalized browsers), controlling metadata leaks (time, language, fingerprinting).</p> </li> <li> <p>Attack surface: Prevent malvertising, malicious downloads, and tracking; employ blocklists, sandboxing, and up-to-date security tools.</p> </li> <li> <p>Minimal interaction: Observe without participating; avoid likes, comments, or messages that could alter the environment or reveal the analyst\u2019s presence.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/osint/limitations-and-ethics/#quality-and-verification","title":"Quality and verification","text":"<ul> <li> <p>Multilevel corroboration: Combine internal verification (consistency, metadata, integrity) with external verification (other independent sources). Apply credibility-reliability matrices and label evidence by confidence level.</p> </li> <li> <p>Chain of custody: Record who obtained what, when, and how; preserve unaltered originals alongside hashes and derived versions for analysis.</p> </li> <li> <p>Human-in-the-loop: Maintain human oversight to review automated outputs, especially for high-impact findings.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/socmint/","title":"SOCMINT","text":"<p>Social Media Intelligence (SOCMINT) is the branch of cyber intelligence dedicated to locating, collecting, processing, and analyzing publicly generated information from social platforms and digital communities (social networks, forums, blogs, public messaging channels, and review sites) with the goal of producing actionable knowledge that supports operational, tactical, or strategic decision-making.</p> <p>SOCMINT does not involve accessing private information or bypassing platform security mechanisms. It operates on publicly available content and metadata (without authentication or with legitimate access) and adheres to principles of legality, proportionality, and respect for privacy. Unlike general OSINT, SOCMINT focuses specifically on the digital social ecosystem as a primary source of intelligence.</p>"},{"location":"cyber-threat-intelligence/socmint/#scope","title":"Scope","text":"<ul> <li> <p>Published content: Texts (posts, comments, titles, descriptions), images, videos, public live streams, and stories.</p> </li> <li> <p>Explicit and derived metadata: Dates and times, geolocation, language, client/application used, embedded links, tags/hashtags, mentions. When legitimately accessible, this also includes image EXIF data and technical clues that assist verification.</p> </li> <li> <p>Interaction graphs and dynamics: Followers/following relationships, mentions, replies, reposts, groups, and lists; detection of communities, influential nodes, and information flows.</p> </li> <li> <p>Behavioral signals: Posting cadence and schedules, repetition of templates, account synchrony, possible indicators of automation or coordination.</p> </li> <li> <p>Multi-source context: Correlation with news, official open data, internet technical data (WHOIS/DNS/certificates), satellite imagery, or open sensors to strengthen verification.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/socmint/#use-cases","title":"Use cases","text":"<ul> <li> <p>Disinformation detection: Identifying disinformation campaigns and emerging narratives; spotting orchestrated accounts or bots.</p> </li> <li> <p>Incident analysis and fact-checking: Verifying events through geolocation, timelines of posts, and cross-referencing with other sources.</p> </li> <li> <p>Risk assessment and reputation monitoring: Monitoring organizations, sectors, or critical infrastructure for potential threats and reputational issues.</p> </li> <li> <p>Community profiling: Non-intrusive mapping of communities to understand actors, affinities, and influence vectors.</p> </li> <li> <p>Cyber threat investigation support: Linking aliases, domains, and activity patterns to known campaigns for threat analysis.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/socmint/#platforms","title":"Platforms","text":"<p>Currently, social media intelligence relies on a mosaic of environments, each with different dynamics and limitations. X (formerly Twitter) remains the fastest channel for capturing early signals and live conversations, although its APIs and access limits are more restrictive; it requires well-defined lists and search terms, along with immediate archiving.  </p> <p>TikTok dominates short-form video consumption: investigations focus on hashtags, sounds, challenges, and pinned comments. Explicit geolocation is limited, and visual inference plays a central role.  </p> <p>Instagram/Facebook (Meta ecosystem) combine Reels, posts, and public groups (topic-centric) and Marketplaces, which are useful for detecting fraud, account sales, and scams; interface changes are frequent.  </p> <p>LinkedIn provides corporate SOCMINT (career paths, talent movements, job postings, and partnerships) with a strong emphasis on ToS compliance and minimizing personal data.  </p> <p>Reddit hosts topic-based communities with active moderation; research relies on threads, wikis, and discussion timelines.  </p> <p>YouTube and livestreams offer live content and automatic transcriptions valuable for search and summarization; live chats provide additional context.  </p> <p>Telegram (public channels and supergroups) and Discord (servers with open channels) have become semi-public diffusion hubs; external indexing is partial, and strict OPSEC is required (observation without interaction).  </p> <p>Meanwhile, federated networks like Mastodon or Bluesky expand the spectrum with distributed search and lower centralization and, in some geographic contexts, regional platforms (e.g., VK, Weibo) can be critical for coverage.</p> <p></p>"},{"location":"cyber-threat-intelligence/socmint/metadata/","title":"Metadata","text":"<p>Metadata is the information that is included in addition to the content of a digital file, such as identifiers, dates and times, language, the client/app used, relationships with other accounts, location, counters, etc.</p>"},{"location":"cyber-threat-intelligence/socmint/metadata/#common-fields-by-entity","title":"Common fields by entity","text":"<p>In SOCMINT, analysts usually work with different levels of information, or \u201cfields by entity.\u201d This allows them to systematically organize, analyze, and verify the data.</p> <ul> <li> <p>Account/profile level: Common metadata includes the unique identifier, username and display name, biography, language and time zone, creation date, number of followers/following, and links declared in the bio. These fields allow analysts to assess account maturity, detect sudden changes in the audience, and locate potential sockpuppets (alternate accounts).</p> </li> <li> <p>Post level: Each post retains a <code>post_id</code>, creation timestamp (and, if applicable, edit timestamp), language, publishing source or client, hashtags and mentions, embedded links, as well as interaction counters (likes, shares, replies). These data allow the reconstruction of threads (via <code>conversation_id</code>/<code>thread_id</code>), detection of coordinated spikes, and comparison of narratives over time (timelines).</p> </li> <li> <p>Multimedia level: Images and videos provide resolution, duration, and sometimes EXIF metadata (date/time, device, orientation, and, if not stripped by the platform, GPS coordinates). While many platforms remove EXIF upon upload, the content itself provides visual clues (signage, license plates, terrain, shadows, weather) useful for geolocation and temporal verification.</p> </li> <li> <p>Relationship level (social graph): Edges such as follow, reply, mention, quote/repost, and like describe the interaction structure. Analyzing the graph (communities, centrality, bridges) helps identify influential nodes, propagation paths, and potential coordinated campaigns.</p> </li> </ul>"},{"location":"cyber-threat-intelligence/socmint/metadata/#taxonomy","title":"Taxonomy","text":"Category Examples Technical Metadata Unique identifiers: UUIDs for posts, comments, and users Timestamps: Creation, modification, deletion, interaction Device information: Type, operating system, application version Connection data: IP addresses (even behind VPNs on some platforms), ASNs, providers Advanced fingerprinting: Digital signatures of browsing behavior Session telemetry: Usage patterns, uptime, action sequences Geospatial Metadata Explicit geolocation: GPS coordinates voluntarily shared Implicit geolocation: Location inferred from network connection Mobility patterns: Temporal sequences of locations Proximity data: Bluetooth and NFC information from nearby devices Geographic references: Mentions of places in textual content EXIF metadata: Geographical information embedded in images and videos Relational Metadata Interaction graphs: Communication patterns between users Engagement metrics: Frequency, intensity, and nature of interactions Affiliation data: Membership in groups, communities, and lists Influence patterns: Information cascades and content diffusion Relational timeline: Temporal evolution of connections Messaging metadata: Information about private communications (when available) Behavioral Metadata Activity patterns: Posting schedules, frequency, and rhythms Attention data: Time spent on specific content Linguistic footprints: Stylometry and writing patterns Emotional metadata: Emoji usage patterns, reactions, and sentiment Navigation sequences: User paths through the platform Consumption metadata: Content preferences and viewing time"},{"location":"cyber-threat-intelligence/socmint/metadata/#use-cases","title":"Use cases","text":"<ul> <li>Temporal and Geographical Verification: Cross-checking timestamps with visible weather conditions and solar lighting, or with known public events; using location tags or visual inferences.</li> </ul> Inaccurate geotags <p>Few users enable GPS; many locations are imprecise manual tags.</p> <ul> <li>Narrative Reconstruction: <code>conversation_id</code> and reply/mention relationships make it possible to trace the origin and amplification of a message.</li> <li>Automation Detection: Exact posting cadences, improbable time windows, repeated publishing clients, and template-like texts suggest automated behavior.</li> <li>Lightweight Attribution: Correlating aliases, recurring domains, and activity schedules with other profiles or open forums.</li> <li>Impact Measurement: Reading time-stamped counters (which vary over time) to assess reach and momentum.</li> </ul> Noise and bias <p>Counters may be artificially influenced; some cameras/editors modify EXIF data, or device clocks may be incorrect.</p>"},{"location":"cyber-threat-intelligence/socmint/metadata/#recommendations","title":"Recommendations","text":"<ul> <li> <p>Convert all dates to UTC ISO 8601 and retain the platform\u2019s original timestamp value.</p> </li> <li> <p>Preserve evidence by saving captures (HTML/PDF/images) and media hashes.</p> </li> <li> <p>Version edited posts and clarify whether counters reflect the time of collection.</p> </li> <li> <p>Tag language and detect character encodings to avoid search errors.</p> </li> <li> <p>Model data as a graph (nodes: accounts/posts/locations; edges: interactions) to facilitate community analysis.</p> </li> </ul>"},{"location":"ethical-hacking/","title":"Ethical hacking","text":""},{"location":"ethical-hacking/#limitations-and-considerations","title":"Limitations and considerations","text":"<p>Any penetration test on systems that do not belong to you, which has not been previously agreed upon and contracted, is illegal and may lead the company to take action against the individual or group performing the tests. Therefore, the following practices described must be carried out only with the authorization of the target organization.</p>"},{"location":"ethical-hacking/fundamentals/","title":"Fundamentals","text":""},{"location":"ethical-hacking/fundamentals/#definition-of-ethical-hacking","title":"Definition of ethical hacking","text":"<p>The term ethical hacking is used in the field of cybersecurity to refer to an authorized intrusion test on a company's systems and networks in a controlled manner. The goal of ethical hacking is to identify threats and vulnerabilities in systems that a malicious attacker could find and exploit, potentially causing significant damage.</p>"},{"location":"ethical-hacking/fundamentals/#types-of-audits","title":"Types of audits","text":"<p>There are different types of penetration tests that can be performed, based on where they are conducted, the information available, and the type of attack being simulated.</p>"},{"location":"ethical-hacking/fundamentals/#black-box","title":"Black box","text":"<p>A black box audit is highly demanded because it simulates a real attack by a malicious hacker. In this type of audit, the tests are usually performed remotely and the professional is not provided with any technical documentation, network maps, or system user information.</p> <p>Since no prior information is available, it is very important to strictly follow the phases of a penetration test and to be highly organized when collecting information and gathering evidence as it is discovered.</p>"},{"location":"ethical-hacking/fundamentals/#white-box","title":"White box","text":"<p>This is the stage where the auditor has more work, but also higher chances of success during the penetration test. In a white box audit, all the necessary information to carry out the intrusion test is provided, including users with different privilege levels, network maps, firewalls, applications, etc.</p> <p>This type of test usually takes longer, as it requires analyzing many components of the infrastructure, as well as performing an exhaustive software assessment, including code review and analysis of installed system versions.</p>"},{"location":"ethical-hacking/fundamentals/#gray-box","title":"Gray box","text":"<p>A gray box audit lies between a white box audit and a black box audit. These assessments are usually conducted partially remotely and partially on the client\u2019s premises, so that it can be tested the external infrastructure without neglecting the company\u2019s internal security.</p> <p>The auditor is provided with infrastructure data, user accounts (usually without privileges), general information about the applications under analysis, and specific instructions regarding the components to be tested.</p> <p>Internal attacks or data leaks are often caused by disgruntled employees who have access to infrastructure information and system access, typically with limited user privileges. This provided information allows the auditor to better understand the infrastructure, making the penetration test easier; however, it must also be taken into account that there are more components that need to be analyzed.</p>"},{"location":"ethical-hacking/fundamentals/methodologies/","title":"Methodologies","text":"<p>To perform a penetration test, it is necessary to follow a methodology. This ensures that no attack vector is overlooked and that the work can be validated and recognized by other professionals. It is considered good practice to state which methodology has been followed when conducting a penetration test, as it facilitates future re-tests and provides overall consistency to the final results.</p> <p>Below is an overview of the most widely used methodologies in the information security industry, developed through collaboration among professionals from different countries.</p>"},{"location":"ethical-hacking/fundamentals/methodologies/#osstmm","title":"OSSTMM","text":"<p>The OSSTMM standard (Open Source Security Testing Methodology) is one of the most widely recognized standards in the industry, providing a scientific methodology for network penetration testing and vulnerability assessment. This methodology is based on the tester\u2019s in-depth knowledge and experience, as well as on human intelligence to interpret the identified vulnerabilities and their potential impact within the network.</p>"},{"location":"ethical-hacking/fundamentals/methodologies/#owasp","title":"OWASP","text":"<p>For everything related to application security, the Open Web Application Security Project (OWASP) is the most widely recognized standard in the cybersecurity industry. This methodology, driven by a highly skilled community that stays up to date with the latest technologies, has helped countless organizations mitigate application vulnerabilities.</p>"},{"location":"ethical-hacking/fundamentals/methodologies/#ptes","title":"PTES","text":"<p>PTES (Penetration Testing Execution Standard) highlights the most recommended approach for structuring a penetration test. This standard guides professionals through the various stages of a penetration test, including initial communication, information gathering, and threat modeling phases.</p>"}]}